{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d8692f",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "### Deteccion de anomalias usando autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2745ae",
   "metadata": {},
   "source": [
    "Anomaly Detection using AutoEncoders\n",
    "\n",
    "AutoEncoders are widely used in anomaly detection. _The reconstruction errors are used as the anomaly scores_. Let us look at how we can use AutoEncoder for anomaly detection using TensorFlow.\n",
    "\n",
    "Import the required libraries and load the data. Here we are using the ECG data which consists of labels 0 and 1. Label 0 denotes the observation as an anomaly and label 1 denotes the observation as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ccd348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 22:09:17.514446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 22:09:17.912398: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-25 22:09:18.665612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-25 22:09:18.665667: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-25 22:09:18.665672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1 -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2 -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3  0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4  0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "\n",
       "        7         8         9    ...       131       132       133       134  \\\n",
       "0 -1.818286 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958  0.578621   \n",
       "1 -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490  0.724046   \n",
       "2 -1.490659 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377 -0.021919   \n",
       "3 -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345  0.842069   \n",
       "4 -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025  1.371682   \n",
       "\n",
       "        135       136       137       138       139  140  \n",
       "0  0.257740  0.228077  0.123431  0.925286  0.193137  1.0  \n",
       "1  0.555784  0.476333  0.773820  1.119621 -1.436250  1.0  \n",
       "2 -0.713683 -0.532197  0.321097  0.904227 -0.421797  1.0  \n",
       "3  0.952074  0.990133  1.086798  1.403011 -0.383564  1.0  \n",
       "4  1.277392  0.960304  0.971020  1.614392  1.421456  1.0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "\n",
    "# Download the dataset\n",
    "PATH_TO_DATA = 'http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv'\n",
    "data = pd.read_csv(PATH_TO_DATA, header=None)\n",
    "data.head()\n",
    "\n",
    "# data shape\n",
    "# (4998, 141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbd341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 141)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e9af54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2919\n",
       "0.0    2079\n",
       "Name: 140, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,140].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656efe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last column is the target\n",
    "# 0 = anomaly, 1 = normal\n",
    "TARGET = 140\n",
    "\n",
    "features = data.drop(TARGET, axis=1)\n",
    "target = data[TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, stratify=target\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9949ee3",
   "metadata": {},
   "source": [
    "Como lo que nos interesa es detectar cuales son los novedosos, usamos solo los datos normales para entrenar (queremos provocar la diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d9673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = y_train[y_train == 1].index\n",
    "train_data = x_train.loc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5450ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max scale the input data\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_scaled = min_max_scaler.fit_transform(train_data.copy())\n",
    "x_test_scaled = min_max_scaler.transform(x_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229100ca",
   "metadata": {},
   "source": [
    "The last column in the data is the target ( column name is 140). Split the data for training and testing and scale the data using MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87da6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 22:15:25.785694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:25.826140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:25.826458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:25.827151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 22:15:25.828075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:25.828372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:25.828533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:26.512672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:26.513182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:26.513466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 22:15:26.513594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6049 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:06:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 43ms/step - loss: 0.0113 - mse: 0.0256 - val_loss: 0.0138 - val_mse: 0.0320\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0111 - mse: 0.0250 - val_loss: 0.0137 - val_mse: 0.0316\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0242 - val_loss: 0.0134 - val_mse: 0.0310\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0228 - val_loss: 0.0130 - val_mse: 0.0301\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0091 - mse: 0.0205 - val_loss: 0.0127 - val_mse: 0.0293\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - mse: 0.0181 - val_loss: 0.0127 - val_mse: 0.0293\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0122 - val_mse: 0.0281\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0065 - mse: 0.0145 - val_loss: 0.0117 - val_mse: 0.0271\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0060 - mse: 0.0133 - val_loss: 0.0116 - val_mse: 0.0267\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0125 - val_loss: 0.0114 - val_mse: 0.0262\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0120 - val_loss: 0.0111 - val_mse: 0.0256\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 0.0115 - val_loss: 0.0110 - val_mse: 0.0254\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0112 - val_loss: 0.0107 - val_mse: 0.0246\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0049 - mse: 0.0109 - val_loss: 0.0105 - val_mse: 0.0241\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0107 - val_loss: 0.0103 - val_mse: 0.0237\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0047 - mse: 0.0106 - val_loss: 0.0102 - val_mse: 0.0235\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0047 - mse: 0.0105 - val_loss: 0.0101 - val_mse: 0.0234\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0104 - val_loss: 0.0101 - val_mse: 0.0233\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0046 - mse: 0.0104 - val_loss: 0.0100 - val_mse: 0.0232\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0046 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0231\n"
     ]
    }
   ],
   "source": [
    "# create a model by subclassing Model class in tensorflow\n",
    "class AutoEncoder(Model):\n",
    "  \"\"\"\n",
    "  Parameters\n",
    "  ----------\n",
    "  output_units: int\n",
    "    Number of output units\n",
    "  \n",
    "  code_size: int\n",
    "    Number of units in bottle neck\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, output_units, code_size=8):\n",
    "    super().__init__()\n",
    "    self.encoder = Sequential([\n",
    "      Dense(64, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(32, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(16, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(code_size, activation='relu')\n",
    "    ])\n",
    "    self.decoder = Sequential([\n",
    "      Dense(16, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(32, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(64, activation='relu'),\n",
    "      Dropout(0.1),\n",
    "      Dense(output_units, activation='sigmoid')\n",
    "    ])\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    encoded = self.encoder(inputs)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
    "# configurations of model\n",
    "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_scaled,\n",
    "    x_train_scaled,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_test_scaled, x_test_scaled)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ac964",
   "metadata": {},
   "source": [
    "The encoder of the model consists of four layers that encode the data into lower dimensions. The decoder of the model consists of four layers that reconstruct the input data.\n",
    "\n",
    "The model is compiled with Mean Squared Logarithmic loss and Adam optimizer. The model is then trained with 20 epochs with a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad491bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSLE Loss')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aae394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 722us/step\n",
      "Threshold: 0.010008066543071445\n",
      "32/32 [==============================] - 0s 708us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.938"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_threshold(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled)\n",
    "    # provides losses of individual instances\n",
    "    reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
    "    # threshold for anomaly scores\n",
    "    threshold = np.mean(reconstruction_errors.numpy()) \\\n",
    "    + np.std(reconstruction_errors.numpy())\n",
    "    return threshold\n",
    "\n",
    "def get_predictions(model, x_test_scaled, threshold):\n",
    "    predictions = model.predict(x_test_scaled)\n",
    "    # provides losses of individual instances\n",
    "    errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
    "    # 0 = anomaly, 1 = normal\n",
    "    anomaly_mask = pd.Series(errors) > threshold\n",
    "    preds = anomaly_mask.map(lambda x: 0.0 if x == True else 1.0)\n",
    "    return preds\n",
    "\n",
    "threshold = find_threshold(model, x_train_scaled)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "# Threshold: 0.01001314025746261\n",
    "predictions = get_predictions(model, x_test_scaled, threshold)\n",
    "accuracy_score(predictions, y_test)\n",
    "\n",
    "# 0.944"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa19e9",
   "metadata": {},
   "source": [
    "The reconstruction errors are considered to be anomaly scores. The threshold is then calculated by summing the mean and standard deviation of the reconstruction errors. The reconstruction errors above this threshold are considered to be anomalies. We can further fine-tune the model by leveraging Keras-tuner.\n",
    "\n",
    " \n",
    "\n",
    "The autoencoder model does not have to symmetric encoder and decoder but the code size has to be smaller than that of the features in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ca654",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction using AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30f90fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import kerastuner.tuners as kt\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32f9e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a0392c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(california.data,columns = california.feature_names)\n",
    "target = pd.DataFrame(california.target,columns = california.target_names)\n",
    "\n",
    "x_train,x_test, y_train,_y_test = train_test_split(data,target,test_size=0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4871a3",
   "metadata": {},
   "source": [
    "Scale the dataset using MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c6f6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_datasets(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Standard Scale test and train data\n",
    "    \"\"\"\n",
    "    standard_scaler = MinMaxScaler()\n",
    "    x_train_scaled = pd.DataFrame(\n",
    "        standard_scaler.fit_transform(x_train),\n",
    "        columns=x_train.columns\n",
    "    )\n",
    "    x_test_scaled = pd.DataFrame(\n",
    "        standard_scaler.transform(x_test),\n",
    "        columns = x_test.columns\n",
    "    )\n",
    "    return x_train_scaled, x_test_scaled\n",
    "  \n",
    "x_train_scaled, x_test_scaled = scale_datasets(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744de78c",
   "metadata": {},
   "source": [
    "Train the autoencoder with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "033f1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "452/452 [==============================] - 2s 2ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.0454 - val_mae: 0.0454\n",
      "Epoch 2/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0286 - mae: 0.0286 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 3/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 4/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 5/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 6/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 7/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 8/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 9/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 10/15\n",
      "452/452 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 11/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 12/15\n",
      "452/452 [==============================] - 1s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 13/15\n",
      "452/452 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 14/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 15/15\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0092 - val_mae: 0.0092\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoders(Model):\n",
    "    def __init__(self, output_units):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential(\n",
    "            [\n",
    "                Dense(32, activation=\"relu\"),\n",
    "                Dense(16, activation=\"relu\"),\n",
    "                Dense(7, activation=\"relu\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.decoder = Sequential(\n",
    "            [\n",
    "                Dense(16, activation=\"relu\"),\n",
    "                Dense(32, activation=\"relu\"),\n",
    "                Dense(output_units, activation=\"sigmoid\")\n",
    "            ]\n",
    "        )\n",
    "        ## AQUI HABIA UN ERROR EN EL PROGRAMA!!\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "auto_encoder = AutoEncoders(len(x_train_scaled.columns))\n",
    "\n",
    "auto_encoder.compile(\n",
    "    loss='mae',\n",
    "    metrics=['mae'],\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history = auto_encoder.fit(\n",
    "    x_train_scaled, \n",
    "    x_train_scaled, \n",
    "    epochs=15, \n",
    "    batch_size=32, \n",
    "    validation_data=(x_test_scaled, x_test_scaled)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa584a5",
   "metadata": {},
   "source": [
    "Here we have defined the autoencoder model by subclassing the Model class in Tensorflow and we compile the AutoEncoder model with mean absolute error and adam optimization function. We split the data into batches of 32 and we run it for 15 epochs.\n",
    "\n",
    "Get the encoder layer and use the method predict to reduce dimensions in data. Since we have seven hidden units in the bottleneck the data is reduced to seven features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71b44964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452/452 [==============================] - 0s 636us/step\n"
     ]
    }
   ],
   "source": [
    "encoder_layer = auto_encoder.get_layer('sequential_14')\n",
    "reduced_df = pd.DataFrame(encoder_layer.predict(x_train_scaled))\n",
    "reduced_df = reduced_df.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f400839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.443627</td>\n",
       "      <td>0.648662</td>\n",
       "      <td>1.239704</td>\n",
       "      <td>2.399297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.388015</td>\n",
       "      <td>1.062739</td>\n",
       "      <td>1.710036</td>\n",
       "      <td>2.307930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644563</td>\n",
       "      <td>2.053547</td>\n",
       "      <td>1.543348</td>\n",
       "      <td>2.768314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.984858</td>\n",
       "      <td>1.342251</td>\n",
       "      <td>1.203275</td>\n",
       "      <td>2.668591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247028</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672619</td>\n",
       "      <td>2.618364</td>\n",
       "      <td>2.022026</td>\n",
       "      <td>2.230176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.241025</td>\n",
       "      <td>0.343856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>1.504106</td>\n",
       "      <td>1.668410</td>\n",
       "      <td>2.095246</td>\n",
       "      <td>2.385668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.307051</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14444</th>\n",
       "      <td>1.632588</td>\n",
       "      <td>0.863038</td>\n",
       "      <td>1.350066</td>\n",
       "      <td>2.235933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514684</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14445</th>\n",
       "      <td>1.079722</td>\n",
       "      <td>1.686312</td>\n",
       "      <td>0.295636</td>\n",
       "      <td>2.553993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14446</th>\n",
       "      <td>0.934954</td>\n",
       "      <td>2.598719</td>\n",
       "      <td>1.691111</td>\n",
       "      <td>2.331264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.851335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14447</th>\n",
       "      <td>0.925894</td>\n",
       "      <td>1.589776</td>\n",
       "      <td>1.445795</td>\n",
       "      <td>2.793630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971635</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14448 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0       1.443627   0.648662   1.239704   2.399297        0.0   0.129634   \n",
       "1       1.388015   1.062739   1.710036   2.307930        0.0   0.713073   \n",
       "2       0.644563   2.053547   1.543348   2.768314        0.0   1.523437   \n",
       "3       1.984858   1.342251   1.203275   2.668591        0.0   0.247028   \n",
       "4       0.672619   2.618364   2.022026   2.230176        0.0   2.241025   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "14443   1.504106   1.668410   2.095246   2.385668        0.0   1.307051   \n",
       "14444   1.632588   0.863038   1.350066   2.235933        0.0   0.514684   \n",
       "14445   1.079722   1.686312   0.295636   2.553993        0.0   0.473992   \n",
       "14446   0.934954   2.598719   1.691111   2.331264        0.0   1.851335   \n",
       "14447   0.925894   1.589776   1.445795   2.793630        0.0   0.971635   \n",
       "\n",
       "       feature_6  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.343856  \n",
       "...          ...  \n",
       "14443   0.000000  \n",
       "14444   0.000000  \n",
       "14445   0.000000  \n",
       "14446   0.000000  \n",
       "14447   0.000000  \n",
       "\n",
       "[14448 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b693d2",
   "metadata": {},
   "source": [
    "In this way, AutoEncoders can be used to reduce dimensions in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d610837",
   "metadata": {},
   "source": [
    "`https://towardsdatascience.com/image-colorization-using-convolutional-autoencoders-fdabc1cb1dbe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd394a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
